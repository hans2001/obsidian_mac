[[codewalk high level overview]]
[[codewalk questions]]
## **Adds**
### `add(left, right)`Â (static)
- **Logic:**
    - Checks whether either operand (`left`Â orÂ `right`) is aÂ `SparseMatrix`.
    - If so, calls the appropriateÂ `AddStrategy`, ensuring theÂ _sparse operand_Â is passed as theÂ **left**Â argument.
    - If neither operand is sparse, routes to theÂ **denseâ€“dense**Â path implemented inÂ `ArrayMatrix.addDenseDense()`.
        
- **Why flip?**  
    `AddStrategy`Â always assumes theÂ **left**Â operand is sparse.  
    So if only theÂ **right**Â matrix is sparse, we swap arguments â€”Â `(right, left)`Â â€” to preserve this invariant. âœ…
    
## **AddStrategy**

- Always assumesÂ **`self`Â is aÂ `SparseMatrix`**.
- Determines the correct addition routine based on theÂ _type_Â of the other operand:
    - If the other is alsoÂ `SparseMatrix`Â â†’ useÂ **AddSparseSparse**.
    - If the other isÂ `ArrayMatrix`Â (dense) â†’ useÂ **AddSparseDense**.
    - Otherwise â†’ throw anÂ `IllegalArgumentException`Â (unsupported matrix type).
---
## **AddSparseDense**

- PerformsÂ **sparse + dense addition**Â as follows:
    1. Create an output matrix byÂ **deep-copying**Â the dense operand.
    2. Iterate throughÂ **nonzero entries**Â in the sparse matrix.
    3. Add each sparse value into the corresponding position of the output.
    4. Optionally drop near-zero results based onÂ `EPS`Â (for sparsity cleanup).
        
## **AddSparseSparse**

- ImplementsÂ **sparse + sparse addition**Â via aÂ **two-pointer merge**:
    - Each row in a sparse matrix is a sorted linked list of entries (by column).
    - Traverse both row lists simultaneously.
    - Merge like a â€œsorted list addition,â€ summing overlapping columns and omitting near-zero results.
        
# **Interface Layer**
## SquareMatrix

- Abstract base interface for all matrix types.
- Defines common public methods such as:
    - `add`,Â `premul`,Â `postmul`,Â `set`,Â `get`,Â `size`,Â `setIdentity`, etc.
- Serves as a unifying API for both dense and sparse implementations.
---
# âš—ï¸Â **Multiplication Choosers**

Utility classes that select the correct multiplication algorithm.

## **Compressed Sparse Row (CSR)**

- Storage format for sparse matrices:
    - Keeps onlyÂ **nonzero entries**.
    - Stores indexing info to know where each row starts and ends.
- Saves memory and speeds up sparse operations by avoiding fullÂ `nÃ—n`Â arrays.

# **Multiplication**
## MulDenseSparsePremul

- Used forÂ **dense Ã— sparse**Â multiplication (`A * B`) whereÂ `A`Â is dense,Â `B`Â is sparse.
- **Outer loop:**Â iterates rows of the dense matrix (`A`).
- **Inner loop:**Â usesÂ `denseColSparseRow(k)`Â to access columnÂ `k`Â ofÂ `A`Â and rowÂ `k`Â ofÂ `B`.
- For each pairÂ `(i, k)`:
    - MultiplyÂ `A[i,k] * B[k, *]`Â (only where both are nonzero).
    - Add scaled row contributions to result:
        `C[i,*] += A[i,k] * B[k,*]`
- This builds each row ofÂ `C`Â viaÂ **scaled-row accumulations**Â rather than element-wise dot products.
---
## MulSparseDensePostmul

- Used forÂ **sparse Ã— dense**Â multiplication (`A * B`) whereÂ `A`Â is sparse,Â `B`Â is dense.
- **Outer loop:**Â iterates over each sparse row ofÂ `A`.
- For each nonzeroÂ `A[i,k]`:
    - Multiply by column values inÂ `B`Â (`B[k, col]`).
    - Accumulate intoÂ `C[i,col]`Â only when both factors are nonzero.
        
- Conceptually also follows:
    `C[i,*] += A[i,k] * B[k,*]`
    (scaled-row accumulation pattern)
    
## MulSparseSparsePremul

- HandlesÂ **sparse Ã— sparse**Â multiplication forÂ `A * B`.
- Similar scaled-row accumulation logic asÂ `MulDenseSparsePremul`,  
    but traversesÂ **only nonzero entries**Â from both operands to minimize computation.
    
## MulSparseSparsePostmul

- PerformsÂ **sparse Ã— sparse**Â post-multiplication by reusing the pre-multiplication algorithm:
    - Simply calls theÂ **premul version**Â withÂ **flipped parameters**.

# ğŸ”—Â **Linked List Structures**

## **RowList / ColList / Entry**

These underpin the sparse matrixâ€™s internal structure.
- **`linkIntoRow(Entry e)`**  
    Inserts a new entry into the linked list for its row, maintaining column sort order.  
    Throws if an entry with the sameÂ `(row, col)`Â already exists.
    
- **`unlink(Entry e)`**  
    Removes an entry from its linked list (used when values drop to zero).
    
- **`iterateRow(int row)`**  
    Returns an iterator for traversing all nonzero entries in a specific row.  
    Implemented as anÂ **anonymous inner iterator**Â with customÂ `hasNext()`Â andÂ `next()`Â methods.
    
## **Iterator (Row traversal)**

- Standard iterator pattern over linked lists:
    - `ret`Â references theÂ **current node**.
    - The globalÂ `cur`Â pointer advances to theÂ **next node**.
    - Returns the current entry reference on each call toÂ `next()`.
- Allows safe traversal without exposing the internal linked-list structure.

# Tests 
## **MatrixTests**
Tests denseâ†’dense, sparseâ†’sparse, and mixed operation paths.

- **`testAdd`**Â â€“ Verifies correct element-wise addition on a small 4Ã—4 dense matrix.
    
- **`testLargeIdentities`**Â â€“ Checks addition and multiplication behavior on large identity matrices (dense) for correctness and performance.
    
- **`testLargeSparseMatrixOperations`**Â â€“ ValidatesÂ `add`,Â `premul`, andÂ `postmul`Â on two large sparse matrices to ensure correctness and no timeouts.
    
- **`testLargeMixedMatrixOperations`**Â â€“ Tests all operations between a large dense (`ArrayMatrix`) and a large sparse (`SparseMatrix`) matrix for proper interoperability.
    
---
## **MatrixTestUtils (static utility class)**
Provides reusable helpers for matrix tests.

- **`assertMatrixEquals`**Â â€“ Deeply compares two matrices element-by-element within a tolerance (epsilon).
    
- **`denseFrom`**Â â€“ Builds a denseÂ `ArrayMatrix`Â from a 2D float array.
    
- **`denseNaiveMul`**Â â€“ Computes a dense reference multiplication (`left Ã— right`) using the naive triple-loop algorithm.
    
- **`toSparse`**Â â€“ Builds aÂ `SparseMatrix`Â from a 2D array, inserting only nonzero entries.
    
---
## **DummyMatrix**
A stub implementation ofÂ `SquareMatrix`Â used to test that unsupported matrix types are correctly rejected by dispatchers.

## **AdditionTest**
### **Dispatcher routing tests**

- **`densePlusSparse_swapsToSparseFirst`**Â â€“ Ensures that when the left operand is dense and the right is sparse, the dispatcher correctly routes to the sparse-first addition strategy (and results are consistent).
    
- **`sparsePlusDense_directSparseFirst`**Â â€“ Confirms that when the left operand is sparse, the dispatcher uses the sparse-first path directly (no swap).
    
- **`densePlusDense_fastKernel`**Â â€“ Validates that dense+dense addition goes through the fast kernel path and produces correct sums.
    
- **`sparsePlusSparse_mergeRowsAndDropZeros`**Â â€“ Checks sparse+sparse row merging, ensuring overlapping entries are summed and near-zero results are dropped.
    
### **EPS threshold behavior**

- **`add_usesEpsThreshold_forZeroSumOmission`**Â â€“ Verifies the EPS zero-tolerance rule: small sums (|x| â‰¤ EPS) are omitted, larger ones retained.

### **Sparse + Dense merge mechanics**

- **`sparseDense_copyThenAdd`**Â â€“ Tests merge correctness and zero-sum cancellation when adding a sparse to a dense matrix.
    
- **`addSparseDense_skipsEmptyRows`**Â â€“ Ensures rows without sparse entries are skipped and unrelated dense values remain unchanged.

### **Sparse + Sparse merge mechanics**

- **`sparseSparse_allMergeCases`**Â â€“ Validates all sparse row-merge scenarios: left-only, right-only, matching columns, and zero-sum cancellations.
    
- **`sparseSparse_rowExhaustionOnBothSides_minimal`**Â â€“ Ensures merging continues correctly when one rowâ€™s entries are exhausted before the otherâ€™s.

# NumbersAndBasicsTest

- **`constructorAndSize`**Â â€“ Checks constructors reject zero size andÂ `size()`Â reports correct dimension.
    
- **`sparseMatrix_constructor_createsEmptyMatrix`**Â â€“ Ensures a newÂ `SparseMatrix`Â starts with all zero values.
    
- **`identityAndZero`**Â â€“ VerifiesÂ `setIdentity()`Â correctly sets diagonal = 1 and others = 0.
    
- **`sparseZeroToleranceInsertUpdateRemove`**Â â€“ Tests sparse insert/remove rules: small or zero values are dropped.
    
- **`strategyDispatchUnsupportedType`**Â â€“ Confirms operations throw on unsupported matrix types (`DummyMatrix`).
    
- **`sparseZeroBoundary_exactlyEps`**Â â€“ Checks EPS boundary: Â±EPS counts as zero, just above EPS is kept.
    
- **`arrayMatrix_boundsChecks`**Â â€“ ValidatesÂ `ArrayMatrix`Â throws for out-of-rangeÂ `get`/`set`Â indices.
    
- **`sparseMatrix_nullAndSizeMismatchGuards`**Â â€“ Ensures sparseÂ `premul`/`postmul`Â reject null or wrong-sized operands.
    
- **`arrayMatrix_setIdentity_zeroesOffDiagonals`**Â â€“ ConfirmsÂ `setIdentity()`Â also clears old off-diagonal values.

# Why Epsilon: 
Floating-point math is never exact, so we define aÂ _numerical zero band_Â (`|x| â‰¤ EPS`) to make computations stable and efficient.
### Definition: **IEEE 754 floating-point**
float x = 0.1f + 0.2f = `0.3000000119f`

In matrix operations â€” especially addition and multiplication â€” numbers oftenÂ **cancel out**: `1.0000001f + (-1.0000000f) â†’ 0.000000119f`

**Thatâ€™s notÂ _exactly_Â zero, but itâ€™sÂ _numerically negligible_.**  
Without an epsilon rule, that residue would stay in your sparse matrix and falsely look like a real entry.
## Sparse matrices rely on pruning tiny entries
Sparse matrices only storeÂ _significant_Â non-zero values.  

Tiny numerical noise below some threshold should beÂ **treated as zero and removed**, or else:
- The matrix slowly fills with junk values (losing sparsity),
- Operations get slower and less memory-efficient,
- Subsequent results drift slightly due to accumulated round-off.

So a tolerance like:
`EPS = 1e-6f if (Math.abs(value) <= EPS) value = 0f;`
acts as aÂ **cleanup rule**: â€œIf itâ€™s effectively zero, drop it.â€